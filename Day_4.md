### Day 4: 学术报告 & 深度学习实践

#### 半监督分类学习: 汪云云博士

分类学习：训练数据--训练->学习模型--预测->新数据

应用：征信评估、文本分类、图像分类

普通的监督分类学习：寻找一个分类函数，能够尽可能好地将数据分为两类。每个数据样本都会被贴上标签进行学习。缺点：标注费时费力，有时候不可取。

半监督分类： 利用大量无标记样本和少量有标记样本进行训练

学习方法：

- 生成式方法：估计参数，期望最大化。
- 大间隔半监督分类方法：使用SVM算法。最大化所有样本上的类间间隔（有标记+无标记）
- 基于图的半监督分类方法：基于流形结构图（以到线段长度为准），然后通过分类函数最小化值。
- 协同训练（**co-training**）方法：分别训练两个学习模型，然后将有信心的样本加入并迭代训练。

学习原理：

- 目的：利用无标号样本帮助提升学习性能。聚类假设、模型假设
- 聚类假设：如果在分布上靠近，互相聚成一类，则符合聚类假设
- 模型假设：符合某一种模型的特征。在这种情况下，就可以使用模型假设。

研究挑战：

- 半监督学习的不安全特性：有时，利用半监督学习可能会造成性能下降。

  原因：部分无标号样本不可靠—>对无标记样本进行选择

- 引入平衡因子，解决半监督学习的不安全问题

相关工作：

1. 弱监督分类学习
2. 迁移机器学习:同构+异构的迁移学习
   - 基于实例的迁移学习
   - 基于特征的迁移学习
   - 基于参数的迁移学习
   - 基于关系的迁移学习

#### 数据处理过程中的隐私保护：杨庚教授





